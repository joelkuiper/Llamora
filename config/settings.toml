[default]
APP_NAME = "Llamora"
# Development default; replace with your own value in production.
SECRET_KEY = "O7T_mOBS765PydhqWAhH1RArhWBEp6hu28Uhf2gN0Xs"
LOG_LEVEL = "INFO"

# --- Server -----------------------------------------------------------
[default.APP]
host = "127.0.0.1"
port = 5000

# --- Feature flags -----------------------------------------------------
[default.FEATURES]
disable_registration = false

# --- Input constraints --------------------------------------------------
[default.LIMITS]
max_tag_length = 64
max_username_length = 30
max_password_length = 128
min_password_length = 8
max_message_length = 12000
max_search_query_length = 512

# --- Trace recall & summarisation ---------------------------------------
[default.TAG_RECALL]
summary_max_chars = 900
summary_input_max_chars = 600
history_scope = 12
max_tags = 4
max_snippets = 8
snippet_max_chars = 160
mode = "summary"
llm_max_tokens = 256
summary_parallel = 1
background_summarize = true
summary_cache_max = 512

# --- Search (semantic + lexical) ----------------------------------------
[default.SEARCH]
recent_limit = 50
recent_suggestion_limit = 8
entry_index_max_elements = 100000
entry_index_allow_growth = false
page_size = 10
initial_page_size = 15
result_window = 100
stream_ttl = 900
stream_max_sessions = 200
stream_global_memory_budget_bytes = "128MiB"

[default.SEARCH.progressive]
k1 = 128
k2 = 10
rounds = 3
batch_size = 1000
max_ms = 1500
poor_match_max_cos = 0.28
poor_match_min_hits = 3

# --- Authentication -----------------------------------------------------
[default.AUTH]
max_login_attempts = 5
login_lockout_ttl = 900
login_failure_cache_size = 2048

# --- Session ------------------------------------------------------------
[default.SESSION]
ttl = 604800

# --- Database -----------------------------------------------------------
[default.DATABASE]
path = "state.sqlite3"
pool_size = 25
pool_acquire_timeout = 10
timeout = 5.0
busy_timeout = 5000
mmap_size = 10485760

# --- Migrations ---------------------------------------------------------
[default.MIGRATIONS]
path = "migrations"
baseline_version = 1
allow_enroll_existing = false

# --- Embedding model & indexing -----------------------------------------
[default.EMBEDDING]
model = "BAAI/bge-small-en-v1.5"
concurrency = 0
global_memory_budget_bytes = "256MiB"

[default.EMBEDDING.chunking]
max_chars = 1200
overlap_chars = 200

[default.EMBEDDING.index]
embed_batch_size = 128
warm_entry_batch = 200

[default.EMBEDDING.vectors]
dtype = "float16"


# --- LLM ---------------------------------------------------------------
[default.LLM.upstream]
host = ""
parallel = 1
ctx_size = 8192
# skip_health_check = false  # set to true when using an external API

[default.LLM.generation]
n_predict       = 2084
stream          = true
stop            = ["<|im_start|>", "<|im_end|>", "<|endoftext|>", "<|end|>"]
n_keep          = -1
cache_prompt    = true

# mirostat        = 2
# mirostat_tau    = 4.5
# mirostat_eta    = 0.12

repeat_penalty  = 1.25
repeat_last_n   = 320
penalize_nl     = true

temperature = 0.7
top_p = 0.8
top_k = 20

[default.LLM.stream]
pending_ttl = 300
queue_limit = 4
repeat_guard_size = 6
repeat_guard_min_length = 12

[default.LLM]
allowed_config_keys = ["temperature"]

[default.LLM.summary]
timeout_seconds = 30.0

# --- UI preferences -----------------------------------------------------
[default.UI]
clock_format = "24h"

[default.LLM.tokenizer]
encoding = "cl100k_base"

[default.LLM.tokenizer.safety_margin]
ratio = 0.1
min_tokens = 128

[default.LLM.chat]
endpoint = "/v1/chat/completions"
model = "local"
# For local llama.cpp (default):
# base_url = "http://127.0.0.1:8081/v1"
# For external APIs, set base_url, model, and api_key (in .secrets.toml or via env):
# base_url = "https://api.openai.com/v1"
# model = "gpt-4o-mini"
# api_key = ""  # prefer .secrets.toml or LLAMORA_LLM__CHAT__API_KEY
timeout_seconds = 30.0
max_retries = 2
parameter_allowlist = [
  "top_k",
  "n_keep",
  "cache_prompt",
  "mirostat",
  "mirostat_tau",
  "mirostat_eta",
  "repeat_penalty",
  "repeat_last_n",
  "penalize_nl",
]
parameters = {}

# --- Prompt templates ---------------------------------------------------
[default.PROMPTS]
template_dir = "../src/llamora/llm/templates"

# --- Cookies & encryption -----------------------------------------------
[default.COOKIES]
name = "llamora"
# Development default; replace with your own value in production.
secret = "K3aRvB6X6lXe9iWvL99XQqSlqSkJ3YTaxqz81uB_ihw="
force_secure = false

# --- Crypto (DEK storage) -----------------------------------------------
[default.CRYPTO]
dek_storage = "session" # or "cookie"


# --- Background workers -------------------------------------------------
[default.WORKERS.index_worker]
max_queue_size = 1024
batch_size = 32
flush_interval = 0.05

[development]
DEBUG = true

[production]
DEBUG = false
